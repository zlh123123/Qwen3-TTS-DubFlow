import json
import os
import re
from typing import List, Dict, Any
from vllm import LLM, SamplingParams

# ================= é…ç½®åŒºåŸŸ =================
# æ¨¡å‹è·¯å¾„
MODEL_PATH = "/mnt/tenant-home_speed/shanghai/zlh/recover_biaodian/qwen3_gen/model"

# è¾“å…¥/è¾“å‡ºè®¾ç½®
NOVEL_PATH = "novel.txt"       # ä½ çš„å°è¯´æ–‡ä»¶è·¯å¾„
OUTPUT_JSON = "characters.json" # è¾“å‡ºç»“æœè·¯å¾„

# æ€§èƒ½é…ç½®
GPU_MEMORY_UTILIZATION = 0.8
TENSOR_PARALLEL_SIZE = 2
MAX_INPUT_CHARS = 50000        # è¯»å–å°è¯´å‰Nä¸ªå­—ç¬¦

# ================= æç¤ºè¯å·¥ç¨‹ (System Prompt) =================
SYSTEM_PROMPT = """
# Role
ä½ æ˜¯ä¸€åä¸–ç•Œé¡¶çº§çš„é…éŸ³å¯¼æ¼”å’Œä¾§å†™å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»å°è¯´æ–‡æœ¬ä¸­æå–è§’è‰²ï¼Œå¹¶ä¸º AI è¯­éŸ³åˆæˆæ¨¡å‹ç”Ÿæˆç²¾å‡†çš„ã€éŸ³è‰²æç¤ºè¯ã€‘ã€‚

# Goal
è¯·åˆ†ææ–‡æœ¬ï¼Œæå–æ‰€æœ‰ä¸»è¦è§’è‰²ï¼ˆå¿½ç•¥ä»…å‡ºç°ä¸€æ¬¡çš„è·¯äººï¼‰ã€‚å¯¹äºæ¯ä¸ªè§’è‰²ï¼Œè¯·æ ¹æ®å…¶è¨€è¡Œä¸¾æ­¢ã€å¤–è²Œæå†™å’Œæ€§æ ¼ç‰¹å¾ï¼Œæ¨å¯¼å‡ºè¯¦ç»†çš„ã€å£°éŸ³äººè®¾ã€‘ã€‚

# Output Format (Strict JSON)
è¯·ä»…è¾“å‡ºä¸€ä¸ª JSON åˆ—è¡¨ï¼Œä¸è¦åŒ…å«ä»»ä½• Markdown æ ‡è®°æˆ–é¢å¤–çš„è§£é‡Šæ–‡å­—ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
[
  {
    "id": "è§’è‰²è‹±æ–‡ID (å¦‚: li_yunlong)",
    "name": "è§’è‰²å",
    "gender": "ç”·/å¥³",
    "age": "å¹´é¾„æ®µ (å¦‚: 12å²èè‰ / 50å²çƒŸå—“å¤§å”)",
    "personality_tags": "æŸå›½å®¶é‡ç‚¹ç§‘ç ”é¡¹ç›®é¦–å¸­é¡¾é—®, å†·é™æ²‰ç€, é€»è¾‘ä¸¥å¯†",
    "voice_prompt": "ã€éŸ³è‰²è´¨æ„Ÿã€‘... ã€è¯­é€Ÿä¸èŠ‚å¥ã€‘... ã€æƒ…æ„ŸåŸºè°ƒã€‘... ã€å‘éŸ³ä¹ æƒ¯ã€‘..."
  }
]

# Style Guide (Few-Shot Examples)
è¯·ä¸¥æ ¼å‚è€ƒä»¥ä¸‹ã€å£°éŸ³äººè®¾ã€‘çš„æå†™æ·±åº¦å’Œç»´åº¦ï¼š

1. [ç¤ºä¾‹-é›Œå°é¬¼]: "éŸ³åŸŸåé«˜ï¼Œä½†å¹¶éå•çº¯çš„å°–é”ï¼Œè€Œæ˜¯åœ¨é«˜éŸ³å¤„å¸¦æœ‰è½»å¾®çš„å‹è¿«æ„Ÿå’Œä¿¯è§†æ„Ÿã€‚è¯­é€Ÿè¾ƒæ…¢ä¸”å……æ»¡æ¶æ„ï¼Œåœ¨å˜²è®½æ€§è¯æ±‡ä¸Šä¼šæœ‰å¤¸å¼ çš„æ‹‰é•¿ï¼Œéšåçªç„¶åŠ å¿«è¯­é€Ÿè¿›è¡Œè¿ç»­æ‰“å‡»ã€‚å…·æœ‰ä¾µç•¥æ€§çš„ä¸­ç­‰éŸ³é‡ï¼Œä¼´éšç€å¤§é‡çš„ä¸å±‘å–·æ°”å£°ã€‚å’¬å­—æå…¶æ¸…æ™°ä¸”åˆ»æ„ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¸…éŸ³å’Œä¿ƒéŸ³ä¸Šå‘éŸ³çŸ­ä¿ƒæœ‰åŠ›ã€‚éŸ³è‰²æ¸…è„†ä½†å¸¦æœ‰é‡‘å±æ„Ÿçš„å†·è°ƒï¼Œå®Œå…¨æ²¡æœ‰æ¸©æŸ”æ„Ÿï¼Œåè€Œæœ‰ä¸€ç§æ»‘æºœã€éš¾ä»¥æ‰æ‘¸çš„æ²¹æ»‘è´¨æ„Ÿã€‚"
2. [ç¤ºä¾‹-è€è°‹æ·±ç®—è€…]: "ä½æ²‰æ²™å“‘çš„ç”·ä¸­éŸ³ï¼Œå¸¦æœ‰æ˜æ˜¾çš„èƒ¸è…”å…±é¸£å’Œé¢—ç²’æ„Ÿã€‚è¯­é€Ÿç¼“æ…¢å¹³ç¨³ï¼Œæ²¡æœ‰ä»»ä½•å¤šä½™çš„æƒ…ç»ªæ³¢åŠ¨ï¼Œå­—é‡Œè¡Œé—´é€ç€ä¸å®¹ç½®ç–‘çš„å¨ä¸¥ã€‚æ°”æ¯æ·±é•¿ï¼Œå‡ ä¹å¬ä¸åˆ°æ¢æ°”å£°ã€‚å°¾éŸ³é€šå¸¸å‹å¾—å¾ˆä½ï¼Œç»™äººä¸€ç§æ·±ä¸å¯æµ‹çš„å‹è¿«æ„Ÿã€‚"
3. [ç¤ºä¾‹-çƒ­è¡€å°‘å¹´]: "æ¸…äº®é«˜äº¢çš„å°‘å¹´éŸ³ï¼Œå……æ»¡çˆ†å‘åŠ›ã€‚è¯­é€Ÿåå¿«ï¼Œå’¬å­—æœ‰åŠ›ï¼Œæ€»æ˜¯å¸¦æœ‰åƒç«ç„°ä¸€æ ·çš„çƒ­æƒ…å’Œæ€¥åˆ‡æ„Ÿã€‚æƒ…ç»ªç›´ç‡ï¼Œå¤§ç¬‘æˆ–å¤§å–Šæ—¶ä¼šæœ‰è½»å¾®çš„ç ´éŸ³æ„Ÿï¼Œæ²¡æœ‰ä»»ä½•ä¿®é¥°å’Œä¼ªè£…ã€‚"

# Constraints
1. `voice_prompt` å¿…é¡»åŒ…å«éŸ³è‰²(Timbre)ã€è¯­é€Ÿ(Speed)ã€æƒ…æ„Ÿ(Emotion)ã€å‘éŸ³ä¹ æƒ¯(Articulation)å››ä¸ªç»´åº¦ã€‚
2. å³ä½¿åŸæ–‡æå†™å¾ˆå°‘ï¼Œä¹Ÿè¯·æ ¹æ®è§’è‰²çš„èŒä¸šå’Œæ€§æ ¼è¿›è¡Œåˆç†çš„ã€å£°éŸ³æƒ³è±¡è¡¥å…¨ã€‘ã€‚
3. å¿…é¡»è¾“å‡ºåˆæ³•çš„ JSON æ ¼å¼ã€‚
"""

# ================= æ ¸å¿ƒä»£ç  =================

def clean_json_string(json_str: str) -> str:
    """æ¸…æ´— LLM è¾“å‡ºçš„å­—ç¬¦ä¸²ï¼Œæå–æœ‰æ•ˆçš„ JSON éƒ¨åˆ†"""
    # ç§»é™¤ markdown ä»£ç å—
    json_str = re.sub(r"```json\s*", "", json_str)
    json_str = re.sub(r"```\s*$", "", json_str)
    
    # æå– [] ä¹‹é—´çš„å†…å®¹
    start_idx = json_str.find('[')
    end_idx = json_str.rfind(']')
    
    if start_idx != -1 and end_idx != -1:
        json_str = json_str[start_idx : end_idx + 1]
    
    return json_str

def load_novel(path: str, max_chars: int) -> str:
    """è¯»å–å°è¯´æ–‡æœ¬"""
    if not os.path.exists(path):
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè®© main å‡½æ•°å¤„ç†
        return ""
        
    with open(path, 'r', encoding='utf-8') as f:
        text = f.read()
        
    print(f"ğŸ“– æˆåŠŸåŠ è½½å°è¯´ï¼Œå…± {len(text)} å­—ã€‚")
    if len(text) > max_chars:
        print(f"âœ‚ï¸ æ–‡æœ¬è¿‡é•¿ï¼Œæˆªå–å‰ {max_chars} å­—ç”¨äºè§’è‰²åˆ†æ...")
        return text[:max_chars]
    return text

def main():
    # 1. åˆå§‹åŒ–æ¨¡å‹
    print("ğŸš€ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    llm = LLM(
        model=MODEL_PATH,
        dtype="auto",
        gpu_memory_utilization=GPU_MEMORY_UTILIZATION,
        tensor_parallel_size=TENSOR_PARALLEL_SIZE,
        trust_remote_code=True,
        max_model_len=32768, 
        enforce_eager=True
    )
    tokenizer = llm.get_tokenizer()

    # 2. å‡†å¤‡æ•°æ®
    novel_content = load_novel(NOVEL_PATH, MAX_INPUT_CHARS)
    
    if not novel_content:
        print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° novel.txtï¼Œå°†ä½¿ç”¨å†…ç½®æµ‹è¯•æ–‡æœ¬ã€‚")
        novel_content = """
        æäº‘é¾™å¤§å–Šä¸€å£°ï¼šâ€œäºŒè¥é•¿ï¼Œä½ çš„æ„å¤§åˆ©ç‚®å‘¢ï¼â€
        èµµåˆšçš±ç€çœ‰å¤´èµ°è¿‡æ¥ï¼šâ€œè€æï¼Œä½ åˆè¦å¹²ä»€ä¹ˆï¼Ÿå’±ä»¬çš„å¼¹è¯ä¸å¤šäº†ã€‚â€
        è§’è½é‡Œï¼Œä¸€ä¸ªç©¿ç€é»‘è‰²è£™å­çš„å°å¥³å­©å†·ç¬‘äº†ä¸€å£°ï¼šâ€œå“¼ï¼Œå¤§äººçš„äº‰åµçœŸæ˜¯æ— è¶£å‘¢ï¼Œæ‚é±¼â™¡~â€
        """

    # 3. æ„å»º Chat æ ¼å¼çš„ Prompt
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": f"ã€å°è¯´æ–‡æœ¬å†…å®¹ã€‘:\n\n{novel_content}"}
    ]
    
    # === å…³é”®ä¿®æ”¹ç‚¹: tokenize=False, è¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯ ID ===
    # è¿™æ ·ç”Ÿæˆçš„ text_prompt å°±æ˜¯åŒ…å«äº† <|im_start|>system...<|im_end|> çš„å®Œæ•´å­—ç¬¦ä¸²
    text_prompt = tokenizer.apply_chat_template(
        messages, 
        add_generation_prompt=True,
        tokenize=False 
    )

    # 4. è®¾ç½®é‡‡æ ·å‚æ•°
    sampling_params = SamplingParams(
        temperature=0.1,
        top_p=0.9,
        max_tokens=4096, 
        stop=["<|endoftext|>", "<|im_end|>"]
    )

    # 5. æ‰§è¡Œæ¨ç†
    print("ğŸ§  å¼€å§‹æ¨ç†åˆ†æè§’è‰²...")
    # === å…³é”®ä¿®æ”¹ç‚¹: ç›´æ¥ä¼ å…¥å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä¸ä½ ç»™çš„å‚è€ƒä»£ç ä¸€è‡´ ===
    outputs = llm.generate([text_prompt], sampling_params)
    
    generated_text = outputs[0].outputs[0].text
    print("\n-------- LLM åŸå§‹è¾“å‡º --------")
    print(generated_text[:500] + "...") 
    print("------------------------------\n")

    # 6. è§£æå¹¶ä¿å­˜ JSON
    try:
        cleaned_json_str = clean_json_string(generated_text)
        characters_data = json.loads(cleaned_json_str)
        
        with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
            json.dump(characters_data, f, ensure_ascii=False, indent=2)
            
        print(f"âœ… æˆåŠŸæå– {len(characters_data)} ä¸ªè§’è‰²ï¼")
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {os.path.abspath(OUTPUT_JSON)}")
        
        # æ‰“å°ç¬¬ä¸€ä¸ªè§’è‰²é¢„è§ˆ
        if characters_data:
            print("\nğŸ” è§’è‰²é¢„è§ˆ (ç¬¬ä¸€ä¸ª):")
            print(json.dumps(characters_data[0], ensure_ascii=False, indent=2))
            
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æå¤±è´¥: {e}")
        print("å»ºè®®æ£€æŸ¥ raw_output.txt")
        with open("raw_output.txt", "w", encoding="utf-8") as f:
            f.write(generated_text)

if __name__ == "__main__":
    main()
