import os
import time
import numpy as np
import soundfile as sf
import torch
import gc
from typing import List, Dict

# è®¾ç½® vLLM ç¯å¢ƒå˜é‡ (å¿…é¡»)
os.environ["VLLM_WORKER_MULTIPROC_METHOD"] = "spawn"

from vllm import SamplingParams
from vllm_omni import Omni

# ================= é…ç½®åŒºåŸŸ =================

# æ¨¡å‹è·¯å¾„ (è¯·ç¡®è®¤è·¯å¾„æ­£ç¡®)
MODEL_PATH_DESIGN = "/root/autodl-tmp/Qwen3-TTS-DubFlow/model/Qwen3-TTS-VoiceDesign"
MODEL_PATH_BASE = "/root/autodl-tmp/Qwen3-TTS-DubFlow/model/Qwen3-TTS-Base"

# è¾“å‡ºç›®å½•
OUTPUT_DIR = "./output_drama_vllm_batch_serve"

# 1. è§’è‰²è®¾å®š
# CHARACTERS_CONFIG = {
#     "Narrator": {
#         "instruct": "Male, energetic podcast host. Casual, engaging, and expressive. Speaks with dynamic pacing, varying pitch to keep the listener hooked. Not robotic at all, sounds like a friend telling a crazy story.",
#         "ref_text": "Welcome back to the show! You are not gonna believe what happened next. It was absolute chaos!" 
#     },
#     "Leo": {
#         "instruct": "Male, British accent (RP). Deep, smooth baritone voice. Sophisticated, calm, and slightly arrogant. Sounds like a villain in a spy movie.",
#         "ref_text": "My dear lady, I'm afraid you have miscalculated the situation entirely."
#     },
#     "Sarah": {
#         "instruct": "Female, American accent. Slightly raspy and husky voice. Confident, sarcastic, and sharp. She has a 'don't mess with me' attitude.",
#         "ref_text": "Cut the crap, Leo. We both know you're bluffing."
#     }
# }

# # 2. å‰§æœ¬å†…å®¹
# SCRIPT = [
#     ("Narrator", "So, picture this. It's midnight in a smoky underground casino in London. The tension? You could cut it with a knife."),
#     ("Leo", "All in. I believe... the Ace of Spades belongs to me."),
#     ("Narrator", "Leo pushes a mountain of chips into the center. He looks cool as a cucumber."),
#     ("Sarah", "You really think you can scare me with that posh accent? Cute."),
#     ("Leo", "It is not about the accent, darling. It is about the cards."),
#     ("Narrator", "Ooh, shots fired! Sarah leans forward, staring right into his soul."),
#     ("Sarah", "Alright then. I call. But if I win, I'm taking that fancy watch of yours too."),
#     ("Leo", "Ha! You are welcome to try. But I must warn you, I never lose."),
#     ("Narrator", "The room goes silent. The dealer flips the final card... It's a Queen of Hearts!"),
#     ("Sarah", "Boom! Full house! Read 'em and weep, Leo!"),
#     ("Leo", "Impossible... How... how did you...?"),
#     ("Sarah", "Like I said. Don't mess with me."),
#     ("Narrator", "And just like that, Leo was broke! Can you believe it? That is why you never play poker with Sarah!"),
# ]

# ================= 1. è§’è‰²æ·±åº¦è®¾å®š (Stress Test: Cyberpunk Crisis) =================
CHARACTERS_CONFIG = {
    "ç³»ç»ŸAI": {
        # æµ‹è¯•ç‚¹ï¼šæœºæ¢°æ„Ÿã€ä¸­è‹±æ··åˆã€æ•°å­—/ä»£ç æœ—è¯»ã€æå¿«è¯­é€Ÿ
        "instruct": "æ— æœºè´¨çš„ç”µå­åˆæˆéŸ³ã€‚è¯­é€Ÿæå¿«ï¼Œæ²¡æœ‰ä»»ä½•æƒ…æ„Ÿæ³¢åŠ¨ï¼Œå‘éŸ³æ ‡å‡†ä½†å†°å†·ã€‚éœ€è¦åœ¨è¿™æ®µè¯é‡Œç²¾å‡†æ¸…æ™°åœ°å¿µå‡ºè‹±æ–‡ç¼©å†™å’Œæ•°å­—ã€‚",
        "ref_text": "Warning. System error 502. æ ¸å¿ƒæ¸©åº¦å·²è¶…è¿‡ 4000 æ‘„æ°åº¦ï¼Œå»ºè®®ç«‹å³å¯åŠ¨ Protocol Zeroã€‚" 
    },
    "æ—åšå£«": {
        # æµ‹è¯•ç‚¹ï¼šæç«¯ææƒ§ã€ç»“å·´ã€æ¢æ°”å£°ã€æ¿’æ­»æ„Ÿçš„é¢¤æŠ–
        "instruct": "30å²ç”·æ€§ï¼Œæåº¦ææ…Œã€‚å£°éŸ³é¢¤æŠ–å‰§çƒˆï¼Œè¯´è¯ä¸Šæ°”ä¸æ¥ä¸‹æ°”ï¼Œå¸¦æœ‰æ˜æ˜¾çš„å“­è…”å’Œç»æœ›æ„Ÿã€‚ç”šè‡³å› ä¸ºå®³æ€•è€Œæœ‰äº›ç ´éŸ³ã€‚",
        "ref_text": "ä¸â€¦â€¦ä¸å¯¹ï¼è¿™æ•°æ®â€¦â€¦å’³å’³â€¦â€¦å®Œå…¨ä¸å¯¹ï¼å®ƒã€å®ƒè¦ç‚¸äº†ï¼æ•‘å‘½ï¼"
    },
    "æŒ‡æŒ¥å®˜": {
        # æµ‹è¯•ç‚¹ï¼šå‹æŠ‘çš„æ„¤æ€’ã€ä½æ²‰å˜¶å“‘ã€å‘½ä»¤å£å»ã€è¯­æ°”è¯
        "instruct": "45å²å¥³æ€§ï¼Œé“è¡€å†›äººã€‚å£°éŸ³ä½æ²‰ã€æ²™å“‘ï¼Œå¸¦æœ‰æå¼ºçš„å‹è¿«æ„Ÿã€‚ä¸æ˜¯å¤§å–Šå¤§å«ï¼Œè€Œæ˜¯å’¬ç‰™åˆ‡é½¿çš„æ„¤æ€’ã€‚",
        "ref_text": "å•§ï¼Œè¯¥æ­»çš„ã€‚æ‰€æœ‰äººå¬ä»¤ï¼Œåˆ‡æ–­è¿æ¥ï¼ç°åœ¨ï¼ç«‹åˆ»ï¼"
    },
    "ç¥ç§˜äºº": {
        # æµ‹è¯•ç‚¹ï¼šæ°”å£°ï¼ˆWhisperï¼‰ã€è½»è”‘ç¬‘å£°ã€é˜´é˜³æ€ªæ°”
        "instruct": "æ€§åˆ«ä¸æ˜ã€‚å£°éŸ³éå¸¸è½»ï¼Œåƒæ˜¯åœ¨è€³è¾¹çš„ä½è¯­ï¼ˆWhisperï¼‰ï¼Œå¸¦ç€ä¸€ç§è½»è”‘å’Œå˜²è®½çš„ç¬‘æ„ã€‚æ°”æ¯æ„Ÿå¾ˆé‡ã€‚",
        "ref_text": "å‘µï¼Œå‘µå‘µå‘µâ€¦â€¦äººç±»çœŸæ˜¯è„†å¼±å•Šã€‚Good nightã€‚"
    }
}

# ================= 2. å‰§æœ¬å†…å®¹ (Scenario: The System Collapse) =================
SCRIPT = [
    # --- æµ‹è¯•ç‚¹1ï¼šä¸­è‹±æ··åˆ + æ•°å­—ä»£ç  ---
    ("ç³»ç»ŸAI", "Alert! Alert! æ£€æµ‹åˆ°æœªçŸ¥ç—…æ¯’ä¾µå…¥ã€‚Error Code: X-99-Beta. å†…å­˜å ç”¨ç‡ 99.9%."),
    
    # --- æµ‹è¯•ç‚¹2ï¼šæ‹Ÿå£°è¯å¤„ç† (æ˜¯è¯»å‡º"å“ˆ"å­—ï¼Œè¿˜æ˜¯çœŸçš„ç¬‘å‡ºå£°) ---
    ("ç¥ç§˜äºº", "å“ˆå“ˆå“ˆå“ˆâ€¦â€¦è¿™å°±æ˜¯ä½ ä»¬çš„é˜²ç«å¢™ï¼Ÿå¤ªå¯ç¬‘äº†ã€‚Access Granted."),
    
    # --- æµ‹è¯•ç‚¹3ï¼šæç«¯ææƒ§ + ç»“å·´ + è¯­æ°”åœé¡¿ ---
    ("æ—åšå£«", "è°ï¼Ÿï¼ä½ æ˜¯è°ï¼Ÿæˆ‘æ˜æ˜â€¦â€¦æ˜æ˜å·²ç»æŠŠç«¯å£å°é”äº†ï¼ä¸ºä»€ä¹ˆâ€¦â€¦ä¸ºä»€ä¹ˆè¿˜æ˜¯â€¦â€¦"),
    
    # --- æµ‹è¯•ç‚¹4ï¼šæå¿«è¯­é€Ÿæ’­æŠ¥ (Tongue Twister style) ---
    ("ç³»ç»ŸAI", "è­¦å‘Šï¼šæ‰‡åŒºAã€æ‰‡åŒºBã€æ‰‡åŒºC1è‡³C9å…¨éƒ¨ç¦»çº¿ã€‚å†·å´æ¶²æ³„æ¼é€Ÿç‡æ¯ç§’äº”ç™¾å‡ã€‚å€’è®¡æ—¶ï¼šTen, Nine, Eight..."),
    
    # --- æµ‹è¯•ç‚¹5ï¼šæ„¤æ€’çš„å’†å“® (æ£€æµ‹çˆ†éŸ³å’Œæƒ…æ„Ÿå¼ åŠ›) ---
    ("æŒ‡æŒ¥å®˜", "æ—é»˜ï¼ä½ åœ¨å¹²ä»€ä¹ˆï¼æˆ‘è®©ä½ æ‹”æ‰ç”µæºï¼å¬åˆ°æ²¡æœ‰ï¼æ‹”æ‰å®ƒï¼ï¼"),
    
    # --- æµ‹è¯•ç‚¹6ï¼šç‰¹å®šçš„å‘éŸ³æ­§ä¹‰ (æ¯”å¦‚ 'è¡Œ' æ˜¯ xing è¿˜æ˜¯ hang) ---
    ("æ—åšå£«", "ä¸â€¦â€¦ä¸è¡Œï¼æ‰‹æŸ„å¡ä½äº†ï¼å®ƒé”æ­»äº†ï¼æˆ‘åŠ¨ä¸äº†ï¼å•Šï¼ï¼ï¼"),
    
    # --- æµ‹è¯•ç‚¹7ï¼šä½è¯­/æ°”å£° (Whisper) ---
    ("ç¥ç§˜äºº", "å˜˜â€¦â€¦å®‰é™ç‚¹ã€‚åœ¨è¿™ä¸ªé¢‘ç‡ä¸‹ï¼Œæ²¡äººèƒ½å¬åˆ°ä½ çš„å°–å«ã€‚å†è§äº†ï¼ŒDoctor."),
    
    # --- æµ‹è¯•ç‚¹8ï¼šé•¿éš¾å¥ + ä¸“ä¸šæœ¯è¯­ ---
    ("ç³»ç»ŸAI", "æ­£åœ¨æ‰§è¡Œæ ¼å¼åŒ–ç¨‹åºã€‚Deleting neural link interface config and biometrics data. å®Œæˆåº¦ 100%ã€‚"),
    
    ("æŒ‡æŒ¥å®˜", "â€¦â€¦è¯¥æ­»ã€‚"),
]

# ================= è¾…åŠ©å‡½æ•° =================

def cleanup_vllm(omni_instance):
    """å¼ºåˆ¶é”€æ¯ vLLM å®ä¾‹å¹¶é‡Šæ”¾æ˜¾å­˜"""
    if omni_instance:
        del omni_instance
    gc.collect()
    torch.cuda.empty_cache()
    print("ğŸ§¹ VRAM Cleaned.")

def parse_req_id(request_id_str):
    """è§£æ vLLM è¿”å›çš„å¤æ‚ request_idï¼Œæå–æ•°å­—ç´¢å¼•"""
    try:
        req_str = str(request_id_str)
        if '_' in req_str:
            return int(req_str.split('_')[0])
        return int(req_str)
    except:
        return -1

# ================= ä¸»ç¨‹åº =================

def main():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    total_start_time = time.perf_counter()

    # ==================================================================
    # Stage 1: Batch Voice Design (å¹¶è¡Œæäºº)
    # ==================================================================
    print("\n" + "="*60)
    print("ğŸ¨ [Stage 1] Batch Voice Design (Baking Voices)...")
    print("="*60)
    t1_start = time.perf_counter()

    # 1. æ„é€  Batch Inputs (ä¸¥æ ¼éµå¾ªå®˜æ–¹ Demo æ ¼å¼)
    design_inputs = []
    design_meta = [] # ç”¨æ¥è®°å½• request_id å¯¹åº”çš„è§’è‰²å

    # éå†å­—å…¸æ„é€ åˆ—è¡¨
    for name, config in CHARACTERS_CONFIG.items():
        text = config["ref_text"]
        instruct = config["instruct"]
        
        # å®˜æ–¹æ¨è Prompt æ ¼å¼
        prompt = f"<|im_start|>assistant\n{text}<|im_end|>\n<|im_start|>assistant\n"
        
        design_inputs.append({
            "prompt": prompt,
            "additional_information": {
                "task_type": ["VoiceDesign"], # å¿…é¡»æ˜¯åˆ—è¡¨
                "text": [text],
                "language": ["Auto"], # æˆ–è€… "English"
                "instruct": [instruct],
                "max_new_tokens": [2048],
                "non_streaming_mode": [True],
            },
        })
        design_meta.append(name)

    # 2. åˆå§‹åŒ–æ¨¡å‹ & æ¨ç†
    omni_design = Omni(model=MODEL_PATH_DESIGN, log_stats=False)
    # é‡‡æ ·å‚æ•°å»ºè®®ï¼šTemperature 0.9 ä¿è¯å¤šæ ·æ€§ï¼ŒTop-P 1.0
    sampling_params = SamplingParams(temperature=0.9, top_p=1.0, max_tokens=2048)
    
    print(f"ğŸ”¥ Designing {len(design_inputs)} voices in parallel...")
    generator = omni_design.generate(design_inputs, [sampling_params])

    ref_wav_paths = {}

    # 3. å¤„ç†ç»“æœ
    for stage_outputs in generator:
        for res in stage_outputs.request_output:
            req_id = parse_req_id(res.request_id)
            
            if 0 <= req_id < len(design_meta):
                role_name = design_meta[req_id]
                audio_tensor = res.multimodal_output["audio"]
                sr = res.multimodal_output["sr"].item()
                
                # è½¬ Numpy
                audio_numpy = audio_tensor.float().detach().cpu().numpy()
                if audio_numpy.ndim > 1: audio_numpy = audio_numpy.flatten()
                
                # ä¿å­˜
                save_path = os.path.join(OUTPUT_DIR, f"ref_{role_name}.wav")
                sf.write(save_path, audio_numpy, samplerate=sr, format="WAV")
                
                ref_wav_paths[role_name] = os.path.abspath(save_path)
                print(f"   -> [ReqID:{req_id}] Generated: {role_name}")

    t1_end = time.perf_counter()
    print(f"âœ… Stage 1 Done ({t1_end - t1_start:.2f}s)")
    
    # å¿…é¡»æ¸…ç†ï¼Œå¦åˆ™ Stage 2 çˆ†æ˜¾å­˜
    cleanup_vllm(omni_design)

    # ==================================================================
    # Stage 2: Batch Base Clone (å¹¶è¡Œåˆæˆå‰§æœ¬)
    # ==================================================================
    print("\n" + "="*60)
    print("ğŸ§Š [Stage 2] Batch Synthesis (Base Clone)...")
    print("="*60)
    t2_start = time.perf_counter()

    # 1. æ„é€  Batch Inputs
    base_inputs = []
    
    for i, (role, text) in enumerate(SCRIPT):
        # æ ¡éªŒæ˜¯å¦æœ‰å‚è€ƒéŸ³é¢‘
        if role not in ref_wav_paths:
            print(f"âŒ Error: Missing ref audio for {role}, skipping line {i}")
            continue
            
        ref_audio_path = ref_wav_paths[role]
        ref_text = CHARACTERS_CONFIG[role]["ref_text"]
        
        prompt = f"<|im_start|>assistant\n{text}<|im_end|>\n<|im_start|>assistant\n"
        
        base_inputs.append({
            "prompt": prompt,
            "additional_information": {
                "task_type": ["Base"],
                "ref_audio": [ref_audio_path], # ä¼ å…¥ç»å¯¹è·¯å¾„
                "ref_text": [ref_text],
                "text": [text],
                "language": ["Auto"],
                "x_vector_only_mode": [False], # False = ICLæ¨¡å¼ (æ•ˆæœæ›´å¥½)
                "max_new_tokens": [2048],
            },
        })

    # 2. åˆå§‹åŒ–æ¨¡å‹ & æ¨ç†
    omni_base = Omni(model=MODEL_PATH_BASE, log_stats=False)
    
    print(f"ğŸ¬ Synthesizing {len(base_inputs)} lines in parallel...")
    generator = omni_base.generate(base_inputs, [sampling_params])

    # ä½¿ç”¨å­—å…¸æš‚å­˜ç»“æœï¼Œä»¥æ”¯æŒä¹±åºè¿”å›
    results_map = {} # {req_id: (wav, sr)}

    for stage_outputs in generator:
        for res in stage_outputs.request_output:
            req_id = parse_req_id(res.request_id)
            
            if 0 <= req_id < len(SCRIPT):
                audio_tensor = res.multimodal_output["audio"]
                sr = res.multimodal_output["sr"].item()
                audio_numpy = audio_tensor.float().detach().cpu().numpy()
                if audio_numpy.ndim > 1: audio_numpy = audio_numpy.flatten()
                
                results_map[req_id] = (audio_numpy, sr)
                
                # å®æ—¶æ˜¾ç¤ºè¿›åº¦
                role = SCRIPT[req_id][0]
                print(f"   -> [ReqID:{req_id}] Synthesized: {role} ", end="\r")

    print("\n")
    t2_end = time.perf_counter()
    print(f"âœ… Stage 2 Done ({t2_end - t2_start:.2f}s)")
    
    cleanup_vllm(omni_base)

    # ==================================================================
    # Stage 3: Concatenation (æ‹¼æ¥)
    # ==================================================================
    print("\n" + "="*60)
    print("ğŸ’¾ [Stage 3] Concatenating Audio...")
    print("="*60)
    
    final_audio = []
    sample_rate = 0
    
    # æŒ‰ç…§å‰§æœ¬é¡ºåºæ‹¼æ¥
    for i in range(len(base_inputs)):
        if i in results_map:
            wav, sr = results_map[i]
            sample_rate = sr
            
            # ä¿å­˜å•å¥ (Debug ç”¨)
            role = SCRIPT[i][0]
            sf.write(os.path.join(OUTPUT_DIR, f"{i:02d}_{role}.wav"), wav, sr)
            
            final_audio.append(wav)
            # æ·»åŠ  0.5s é™éŸ³ï¼Œè®©å¯¹è¯æ›´æœ‰å‘¼å¸æ„Ÿ
            silence = np.zeros(int(sr * 0.5)) 
            final_audio.append(silence)
        else:
            print(f"âš ï¸ Warning: Line {i} failed generation.")

    if final_audio and sample_rate > 0:
        full_audio_data = np.concatenate(final_audio)
        output_path = os.path.join(OUTPUT_DIR, "full_drama_batch.wav")
        sf.write(output_path, full_audio_data, sample_rate)
        
        # æ‰“å°æ€§èƒ½æŠ¥å‘Š 
        print("\nğŸ“Š [Performance Report]")
        print(f"Design Time (3 voices):  {t1_end - t1_start:.2f}s")
        print(f"Clone Time ({len(SCRIPT)} lines):   {t2_end - t2_start:.2f}s")
        print(f"Total Time:              {time.perf_counter() - total_start_time:.2f}s")
        print(f"Saved to: {output_path}")

if __name__ == "__main__":
    main()