import torch
import soundfile as sf
import numpy as np
import os
from tqdm import tqdm
# è¯·æ›¿æ¢ä¸ºä½ å®é™…çš„åº“å¯¼å…¥æ–¹å¼ï¼Œå¦‚æœæ˜¯åœ¨ qwen ä»“åº“æ ¹ç›®å½•è¿è¡Œï¼Œé€šå¸¸å¦‚ä¸‹ï¼š
from qwen_tts import Qwen3TTSModel 

# ================= é…ç½®åŒºåŸŸ =================

# 1. è§’è‰²è®¾å®š (Copy è‡ªä½ çš„éœ€æ±‚)
CHARACTERS_CONFIG = {
    "æ—ç™½": {
        "instruct": "å£°éŸ³ç‰¹å¾æ²‰ç¨³ã€å®¢è§‚ã€ç•¥å¸¦å™äº‹æ„Ÿçš„å¥³æ’­éŸ³è…”ï¼Œæ™®é€šè¯æ ‡å‡†ï¼Œè¯­é€Ÿé€‚ä¸­ï¼Œå¸¦æœ‰è½»å¾®çš„ç¯å¢ƒæ°›å›´æ¸²æŸ“ï¼Œè¯­è°ƒå¹³ç¼“ä½†å¯Œæœ‰æ„ŸæŸ“åŠ›ï¼Œåœ¨å…³é”®æƒ…èŠ‚æ—¶ç¨ä½œåœé¡¿ï¼Œå¢å¼ºç”»é¢æ„Ÿã€‚æƒ…æ„Ÿå†·é™æ—è§‚ï¼Œå¶å°”å¸¦ä¸€ä¸å¾®å¦™çš„åè®½",
        "ref_text": "å°æ—ä»Šå¤©ç¬¬ä¸‰æ¬¡èµ°ç¥äº†ã€‚é…’å§æ˜é»„çš„ç¯å…‰æ™ƒå¾—ä»–å¿ƒè·³åŠ é€Ÿã€‚" 
    },
    "å°æ—": {
        "instruct": "25å²ç”·æ€§ä¸Šç­æ—ï¼Œå£°éŸ³æ¸…äº®ä½†æ—¶å¸¸çŠ¹è±«ï¼Œè¯­é€Ÿæ—¶å¿«æ—¶æ…¢ï¼Œç´§å¼ æ—¶ä¼šè½»å¾®ç»“å·´ã€‚æƒ…ç»ªæ³¢åŠ¨æ˜æ˜¾ï¼Œä»ä½å£°å‘¢å–ƒåˆ°çªç„¶æ¿€åŠ¨å†åˆ°è‡ªæˆ‘æ€€ç–‘çš„å¹æ°”ã€‚è‚¢ä½“è¯­è¨€ä¸°å¯Œï¼Œç»å¸¸æ— æ„è¯†çš„å°åŠ¨ä½œ",
        "ref_text": "å•Šï¼Ÿæˆ‘ã€æˆ‘â€¦â€¦æˆ‘å…¶å®ä¸å¤ªä¼šå–é…’â€¦â€¦"
    },
    "å¾¡å§": {
        "instruct": "æ¨¡æ‹Ÿæˆç†Ÿæ€§æ„Ÿçš„å¾¡å§éŸ³è‰²ï¼Œå£°éŸ³ç•¥å¸¦ç£æ€§ä¸”æ²‰ç¨³ï¼Œè¯­é€Ÿä¸å¿«ä¸æ…¢ï¼Œè¯­è°ƒå……æ»¡è‡ªä¿¡å’Œä¸€ä¸æŒ‘é€—ï¼Œå°¾éŸ³å¯ä»¥ç¨å¾®æ‹–é•¿å¹¶ä¸Šæ‰¬ï¼Œç»™äººä¸€ç§æ¸¸åˆƒæœ‰ä½™çš„æŒæ§æ„Ÿã€‚",
        "ref_text": "å°å¼Ÿå¼Ÿï¼Œæœ‰å…´è¶£é™ªå§å§å–ä¸€æ¯å—ï¼Ÿ"
    }
}

# 2. å‰§æœ¬å†…å®¹
SCRIPT = [
    ("æ—ç™½", "å°æ—ä»Šå¤©ç¬¬ä¸‰æ¬¡èµ°ç¥äº†ã€‚é…’å§æ˜é»„çš„ç¯å…‰æ™ƒå¾—ä»–å¿ƒè·³åŠ é€Ÿï¼Œè€Œå§å°å¯¹é¢é‚£ä¸ªçº¢å”‡å¾®æ‰¬çš„å¥³äººï¼Œæ­£ç”¨æŒ‡å°–è½»è½»æ‘©æŒ²ç€é…’æ¯è¾¹ç¼˜ã€‚"),
    ("å¾¡å§", "å°å¼Ÿå¼Ÿï¼Œæœ‰å…´è¶£é™ªå§å§å–ä¸€æ¯å—ï¼Ÿ"),
    ("å°æ—", "å•Šï¼Ÿæˆ‘ã€æˆ‘â€¦â€¦æˆ‘å…¶å®ä¸å¤ªä¼šå–é…’â€¦â€¦"),
    ("æ—ç™½", "ä»–çš„æ‰‹æŒ‡æ— æ„è¯†åœ°æŠ ç€æ¯æ²¿ï¼Œå–‰ç»“ä¸Šä¸‹æ»šåŠ¨ï¼Œåƒè¢«ä»€ä¹ˆæ— å½¢çš„ä¸œè¥¿æä½äº†å‘¼å¸ã€‚"),
    ("å¾¡å§", "ä¸ä¼šå–ï¼Ÿé‚£æ­£å¥½â€”â€”å§å§æ•™ä½ ã€‚è¿™æ¯è«å‰æ‰˜ï¼Œç”œå¾—åˆšå¥½ï¼Œå°±åƒä½ åˆšæ‰å·çœ‹æˆ‘çš„çœ¼ç¥ã€‚"),
    ("å°æ—", "æˆ‘ã€æˆ‘æ²¡å·çœ‹ï¼â€¦â€¦å¥½å§ï¼Œçœ‹äº†ä¸€çœ¼ã€‚å°±ä¸€çœ¼ï¼"),
    ("æ—ç™½", "ä»–çŒ›åœ°åç›´ï¼Œåˆç«‹åˆ»ç¼©å›è‚©è†€ï¼Œä»¿ä½›é‚£å¥è¯çƒ«ä¼¤äº†è‡ªå·±çš„å˜´ã€‚"),
    ("å¾¡å§", "ç´§å¼ ä»€ä¹ˆï¼Ÿä½ è¿åå§¿éƒ½åœ¨å‘æŠ–â€¦â€¦è¦ä¸è¦é è¿‡æ¥ä¸€ç‚¹ï¼Ÿè¿™é‡Œå¤ªåµäº†ã€‚"),
    ("å°æ—", "é è¿‡å»ï¼Ÿå¯ã€å¯æˆ‘ä»¬æ‰ç¬¬ä¸€æ¬¡è§é¢â€¦â€¦ä½ éƒ½ä¸è®¤è¯†æˆ‘â€¦â€¦"),
    ("å¾¡å§", "åå­—ä¸é‡è¦ï¼Œæ„Ÿè§‰æ‰é‡è¦ã€‚......è€Œæˆ‘æ„Ÿè§‰â€¦â€¦ä½ æœ‰ç‚¹å¯çˆ±ã€‚"),
    ("æ—ç™½", "å°æ—çš„è€³æœµç¬é—´çº¢é€ï¼Œè¿è€³åé‚£é¢—å°ç—£éƒ½åƒåœ¨å‘çƒ«ã€‚ä»–æƒ³é€ƒï¼Œè„šå´åƒé’‰åœ¨äº†é«˜è„šå‡³ä¸Šã€‚"),
    ("å°æ—", "å¯çˆ±ï¼Ÿæ²¡äººè¿™ä¹ˆè¯´è¿‡æˆ‘â€¦â€¦ä»–ä»¬éƒ½è¯´æˆ‘å¤ªé—·ï¼Œè¿æœ‹å‹åœˆéƒ½å‘ä¸å‡ºæ‰‹â€¦â€¦"),
    ("å¾¡å§", "é‚£ç°åœ¨å‘¢ï¼Ÿæ•¢ä¸æ•¢å‘ä¸€æ¡â€”â€”'ä»Šæ™šï¼Œå’Œä¸€ä¸ªå±é™©åˆè¿·äººçš„å§å§å–äº†ä¸€æ¯'ï¼Ÿ"),
    ("å°æ—", "â€¦â€¦æˆ‘è¿é…å›¾éƒ½ä¸æ•¢é€‰ã€‚ä½ ç¬‘èµ·æ¥å¤ªâ€¦â€¦å¤ªæœ‰æ€ä¼¤åŠ›äº†ã€‚"),
    ("å¾¡å§", "é‚£å°±åˆ«å‘äº†ã€‚æœ‰äº›æ•…äº‹ï¼Œåªé€‚åˆè—åœ¨ä¸¤ä¸ªäººçš„è®°å¿†é‡Œâ€”â€”æ¯”å¦‚ï¼Œæ¥ä¸‹æ¥ä½ æ‰“ç®—è¯·æˆ‘è·³æ”¯èˆå—ï¼Ÿ"),
    ("æ—ç™½", "ä»–å¼ äº†å¼ å˜´ï¼Œæ²¡å‘å‡ºå£°éŸ³ã€‚ä½†è¿™ä¸€æ¬¡ï¼Œä»–æ²¡æœ‰ä½å¤´ï¼Œè€Œæ˜¯è½»è½»æ¨å¼€äº†é‚£æ¯æ²¡åŠ¨è¿‡çš„è‹æ‰“æ°´ï¼Œæœå¥¹ä¼¸å‡ºäº†æ‰‹ã€‚")
]

OUTPUT_DIR = "./output_drama_test"

# ================= æ ¸å¿ƒé€»è¾‘ =================

def main():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    # ---------------------------------------------------------
    # Step 1: åŠ è½½ Voice Design æ¨¡å‹ (ç”¨äºç”Ÿæˆå‚è€ƒéŸ³é¢‘)
    # ---------------------------------------------------------
    print("ğŸ¨ [1/3] Loading VoiceDesign Model...")
    design_model = Qwen3TTSModel.from_pretrained(
        "/mnt/tenant-home_speed/shanghai/models/Qwen3-TTS/Qwen3-TTS-12Hz-1.7B-VoiceDesign",
        device_map="cuda:0",
        dtype=torch.bfloat16,
        # attn_implementation="flash_attention_2"
    )

    # ---------------------------------------------------------
    # Step 2: åŠ è½½ Base æ¨¡å‹ (ç”¨äºç”Ÿæˆ Prompt å’Œæœ€ç»ˆå…‹éš†)
    # ---------------------------------------------------------
    print("ğŸ§Š [2/3] Loading Base Model...")
    base_model = Qwen3TTSModel.from_pretrained(
        "/mnt/tenant-home_speed/muiltModel/Qwen3-TTS-12Hz-1.7B-Base",
        device_map="cuda:0", # å¦‚æœæ˜¾å­˜ä¸å¤Ÿï¼Œè¿™é‡Œå¯ä»¥æ”¹åˆ° cuda:1 æˆ–è€… cpu
        dtype=torch.bfloat16,
        # attn_implementation="flash_attention_2"
    )

    # ---------------------------------------------------------
    # Step 3: é“¸é€ éŸ³è‰² (Bake Voices)
    # ---------------------------------------------------------
    print("\nğŸ”¥ [Baking Voices] å¼€å§‹ç”Ÿæˆè§’è‰²éŸ³è‰² Prompt...")
    voice_prompts = {} # ç”¨äºå­˜å‚¨â€œéŸ³è‰²èº«ä»½è¯â€

    for name, config in CHARACTERS_CONFIG.items():
        print(f"   -> å¤„ç†è§’è‰²: {name}")
        
        # 3.1 ä½¿ç”¨ Design æ¨¡å‹ç”Ÿæˆå‚è€ƒéŸ³é¢‘ (wav)
        # è¿™ä¸€æ­¥æ˜¯æŠŠæ–‡å­— instruct å˜æˆå£°éŸ³ wav
        ref_wavs, sr = design_model.generate_voice_design(
            text=config["ref_text"],
            instruct=config["instruct"],
            language="Chinese"
        )
        
        # ä¿å­˜è¿™ä¸ªå‚è€ƒéŸ³é¢‘å¤‡æŸ¥
        ref_wav_path = os.path.join(OUTPUT_DIR, f"ref_{name}.wav")
        sf.write(ref_wav_path, ref_wavs[0], sr)

        # 3.2 ä½¿ç”¨ Base æ¨¡å‹ç”Ÿæˆ Clone Prompt (Tensor)
        # è¿™ä¸€æ­¥æ˜¯æŠŠ wav å˜æˆå¯å¤ç”¨çš„ Tensor
        prompt = base_model.create_voice_clone_prompt(
            ref_audio=(ref_wavs[0], sr),
            ref_text=config["ref_text"]
        )
        
        voice_prompts[name] = prompt

    # (å¯é€‰) å¦‚æœæ˜¾å­˜ç´§å¼ ï¼Œè¿™é‡Œå¯ä»¥ del design_model å¹¶ torch.cuda.empty_cache()

    # ---------------------------------------------------------
    # Step 4: æ‰¹é‡åˆæˆå‰§æœ¬ (Synthesize Drama)
    # ---------------------------------------------------------
    print("\nğŸ¬ [Synthesizing] å¼€å§‹åˆæˆå‰§æœ¬...")
    
    final_audio_list = []
    
    for i, (role, text) in enumerate(tqdm(SCRIPT)):
        # è·å–å¯¹åº”è§’è‰²çš„ Prompt
        prompt = voice_prompts[role]
        
        # è°ƒç”¨ Base æ¨¡å‹è¿›è¡Œå…‹éš†
        # æ³¨æ„ï¼šBase æ¨¡å‹ç”Ÿæˆé€Ÿåº¦å¾ˆå¿«ï¼Œä¸”éŸ³è‰²ä¼šä¸¥æ ¼è·Ÿéš prompt
        wavs, sr = base_model.generate_voice_clone(
            text=text,
            language="Chinese",
            voice_clone_prompt=prompt
        )
        
        # ä¿å­˜åˆ†å¥
        filename = f"{i:02d}_{role}.wav"
        filepath = os.path.join(OUTPUT_DIR, filename)
        sf.write(filepath, wavs[0], sr)
        
        # æ”¶é›†éŸ³é¢‘ç”¨äºæ‹¼æ¥ (åŠ ä¸€ç‚¹ç‚¹é™éŸ³é—´éš” 0.3s)
        silence = np.zeros(int(sr * 0.3))
        final_audio_list.append(wavs[0])
        final_audio_list.append(silence)

    # ---------------------------------------------------------
    # Step 5: æ‹¼æ¥å®Œæ•´éŸ³é¢‘
    # ---------------------------------------------------------
    print("\nğŸ’¾ [Saving] æ­£åœ¨æ‹¼æ¥å®Œæ•´éŸ³é¢‘...")
    full_audio = np.concatenate(final_audio_list)
    full_path = os.path.join(OUTPUT_DIR, "full_drama_result.wav")
    sf.write(full_path, full_audio, sr)
    
    print(f"âœ… å®Œæˆï¼å®Œæ•´å¹¿æ’­å‰§å·²ä¿å­˜è‡³: {full_path}")

if __name__ == "__main__":
    main()
